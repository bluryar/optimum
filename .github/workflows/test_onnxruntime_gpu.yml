name: ONNX Runtime / Python - GPU - Test

on:
  workflow_dispatch:
  pull_request:
    types: [opened, synchronize, reopened, labeled]

concurrency:
  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}
  cancel-in-progress: true

jobs:
  build:
    if: ${{ (github.event_name == 'workflow_dispatch') || contains( github.event.pull_request.labels.*.name, 'gpu-test') }}

    runs-on:
      group: aws-g6-4xlarge-plus

    container:
      image: nvidia/cuda:12.4.1-cudnn-runtime-ubuntu22.04
      options: --gpus all

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: 3.8

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install --no-cache-dir torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124
          pip install .[tests,onnxruntime-gpu] tensorrt

      - name: Replace opencv-python with opencv-python-headless
        run: |
          pip uninstall -y opencv-python && pip install opencv-python-headless

      - name: Update LD_LIBRARY_PATH
        run: |
          export LD_LIBRARY_PATH=$(python -c "import tensorrt; print(tensorrt.__path__[0].replace('/site-packages/tensorrt', '/dist-packages/tensorrt_libs'))"):$LD_LIBRARY_PATH

      - name: Test with pytest
        run: |
          pytest tests/onnxruntime -m "cuda_ep_test or trt_ep_test" --durations=0 -vvvv -s -n auto
